---
layout: post
title:  "cs231n 공부"
date:   2021-08-13
excerpt: ""

tag:
- markdown 
- syntax
- sample
- test
- jekyll
---
{% include toc.html %}


아래는 방학 동안 [cs231n](http://cs231n.stanford.edu/)을 공부하면서 개인적으로 정리 및 필기한 내용이다. 그 외 공부할 때 사용한 자료들은 맨 하단 항목으로 분류해 둘 것이다. 공들여 쓴건 아니고 복습하면서 술렁술렁 쓴 거라 내용은 별로 없을 거 같다.
    
     
     
   
# 1강 : Data-driven approach of image classification
## Image Classification
### 개념
 * 정의 : Image Classification이란 input image를 라벨링하는 것을 의미한다.
    - 예 : 고양이를 'cat'이라는 label로 분류하는 것
 
 * 문제점 : 시점 변화, 크기 변화, 형태 변화, 은폐, 보호색, 착시 등의 문제를 해결하지 못함 
 
 
### PipeLine
* input
* Learning
* Evaluation

## 방법 1 : Nearest Neighbor Classifier
### 개요
1. 메모리 위에 모든 training image와 그에 대응하는 label을 올린다.
2. 후에 테스트 이미지가 주어지면, 해당 이미지를 1에서 저장한 모든 training image와 비교한다.
3. 주어진 image와 <ub>가장 유사한(nearest)</ub> training image의 label을 답으로 내놓는다.

### 가장 유사함(Nearest) 판단기준 : Distance
* Manhattan Distance(L1) 혹은 Euclidean Distance(L2)
 : 링크 참고

    
##  (응용) 방법 1 :  k-Nearest Neighbor Classifier
### 개요
1. 메모리 위에 모든 training image와 그에 대응하는 label을 올린다.  
2. 후에 테스트 이미지가 주어지면, 해당 이미지를 1에서 저장한 모든 training image와 비교한다.  
3. ~~주어진 image와 가장 유사한(nearest) training image의 label을 답으로 내놓는다.~~
    $$\rightarrow$$ 주어진 image와 상위 k개 내로 유사한 training image의 각 label들을 보고, 다수인 label을 답으로 내놓는다.

### 유사함 판단기준 : k개의 Nearest Neighbor
* k는 hyper parameter, 실험을 통해 설정한다.

## Hyperparameter tuning
### Distance
: 상황에 따라 적절한 거리를 사용

### k
: 실험을 통해 가장 classify를 잘 하는 k를 설정한다.
* 주의 ) <URed>k를 설정할 때 절대로 최종 test set을 이용해선 안된다.</URed> overfitting 위험성
$$\rightarrow$$  따라서 k를 설정할 때는 20%정도의 training data를 떼어내서 validation data로 사용한다.
    
### Cross-validation
* training data의 수가 적을 때 k값을 설정하기 위해 사용하는 실험방법
* n-fold cross validation이라고 하면, training set을 n등분하여 n-1개 분할을 training에 사용하고, 1개 분할을 test에 사용하여 accuracy를 측정한다. test에 사용되는 분할을 매번 다른 분할로 선택하면 총 n개의 accuracy 측정결과를 얻을 수 있다. 이를 평균내어 k의 accuracy를 파악하는 지표로 삼는다. k를 바꾸어 가면서 평균 accuracy와 k의 관계를 파악하고, 평균 accuracy를 가장 높이는 k를 선택한다.

## Nearest Neighbor Classifier  vs   k-Nearest Neighbor Classifier
### 1. How does the classification speed depend on the size of the training data?
* Nearest Neighbor Classifier
: Linear
* k-Nearest Neighbor Classifier
: Linear
  
### 2. What is the accuracy of the nearest neighbor classifier on the training data?
* Nearest Neighbor Classifier
: 100%
* k-Nearest Neighbor Classifier
: 상황에 따라 다름

## Pros and Cons of Nearest Neighbor classifier

