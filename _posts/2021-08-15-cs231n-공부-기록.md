---
layout: post
title:  "cs231n 공부 기록"
date:   2021-08-15
excerpt: ""

tag:
- markdown 
- syntax
- sample
- test
- jekyll
---
{% include toc.html %}


아래는 방학 동안 [cs231n](http://cs231n.stanford.edu/)을 공부하면서 개인적으로 정리 및 필기한 내용이다. 그 외 공부할 때 사용한 자료들은 맨 하단 항목으로 분류해 둘 것이다. 공들여 쓴건 아니고 복습하면서 술렁술렁 쓴 거라 내용은 별로 없을 거 같다.
    
     
     
   
# 1강 : Data-driven approach of image classification
## Image Classification
### 개념
 * 정의 : Image Classification이란 input image를 라벨링하는 것을 의미한다.
    - 예 : 고양이를 'cat'이라는 label로 분류하는 것
 
 * 문제점 : 시점 변화, 크기 변화, 형태 변화, 은폐, 보호색, 착시 등의 문제를 해결하지 못함 
 
 
### PipeLine
* input
* Learning
* Evaluation

## 방법 1 : Nearest Neighbor Classifier
### 개요
1. 메모리 위에 모든 training image와 그에 대응하는 label을 올린다.
2. 후에 테스트 이미지가 주어지면, 해당 이미지를 1에서 저장한 모든 training image와 비교한다.
3. 주어진 image와 <ub>가장 유사한(nearest)</ub> training image의 label을 답으로 내놓는다.

### 가장 유사함(Nearest) 판단기준 : Distance
* Manhattan Distance(L1) 혹은 Euclidean Distance(L2)
 : 링크 참고

    
##  (응용) 방법 1 :  k-Nearest Neighbor Classifier
### 개요
1. 메모리 위에 모든 training image와 그에 대응하는 label을 올린다.  
2. 후에 테스트 이미지가 주어지면, 해당 이미지를 1에서 저장한 모든 training image와 비교한다.  
3. ~~주어진 image와 가장 유사한(nearest) training image의 label을 답으로 내놓는다.~~
    $$\rightarrow$$ 주어진 image와 상위 k개 내로 유사한 training image의 각 label들을 보고, 다수인 label을 답으로 내놓는다.

### 유사함 판단기준 : k개의 Nearest Neighbor
* k는 hyper parameter, 실험을 통해 설정한다.

## Hyperparameter tuning
### Distance
: 상황에 따라 적절한 거리를 사용

### k
: 실험을 통해 가장 classify를 잘 하는 k를 설정한다.
* 주의 ) <URed>k를 설정할 때 절대로 최종 test set을 이용해선 안된다.</URed> overfitting 위험성
$$\rightarrow$$  따라서 k를 설정할 때는 20%정도의 training data를 떼어내서 validation data로 사용한다.
    
### Cross-validation
* training data의 수가 적을 때 k값을 설정하기 위해 사용하는 실험방법
* n-fold cross validation이라고 하면, training set을 n등분하여 n-1개 분할을 training에 사용하고, 1개 분할을 test에 사용하여 accuracy를 측정한다. test에 사용되는 분할을 매번 다른 분할로 선택하면 총 n개의 accuracy 측정결과를 얻을 수 있다. 이를 평균내어 k의 accuracy를 파악하는 지표로 삼는다. k를 바꾸어 가면서 평균 accuracy와 k의 관계를 파악하고, 평균 accuracy를 가장 높이는 k를 선택한다.

## Nearest Neighbor Classifier  vs.   k-Nearest Neighbor Classifier
### 1. How does the classification speed depend on the size of the training data?
* Nearest Neighbor Classifier
: Linear
* k-Nearest Neighbor Classifier
: Linear
  
### 2. What is the accuracy of the nearest neighbor classifier on the training data?
* Nearest Neighbor Classifier
: 100%
* k-Nearest Neighbor Classifier
: 상황에 따라 다름

## Pros and Cons of Nearest Neighbor classifier
* 장점
1. 간단하며 구현이 쉽다.
2. training time이 적게 걸린다. 메모리에 올리기만 하면 되기 때문이다.

* 단점  
1. test time이 지나치게 오래 걸린다. training data가 많아질수록 linear하게 증가한다.(cf. deep neural networks)
2. 기본 가정으로부터 '하나의 Image와 동일 distance를 가지는 두 사진은 동일한 사진일 것이다.'라는 결론이 도출되는데, 이는 틀렸다. 이는 distance로부터 similarity를 계산하는 반 직관적 계산방식에서 기인한다.

  $$\rightarrow$$ 이런 이유들 때문에 Nearest Neighbor classifier는 현실에서 많이 사용하지 않는 방식 중 하나이다.

# 2강 : Linear Classification
## Review
### KNN의 단점
1. 모든 training data를 기억해야 한다는 점에서 메모리 낭비가 심하다.
2. 주어진 이미지와 모든 training data를 비교해야 한다는 점에서 test 비용이 비싸다.

## Parameterized mapping from images to label scores
### linear classification 방식
1. 주어진 이미지를 single column vector로 펼친다. [image : Dx1] (D: pixel의 총 개수*3)
2. 그 결과 얻어진 vector에 Weight를 곱한다. [Weight : K  x D] (K : label 개수)
3. 그 결과 얻어진 vector에 bias를 더한다. [bias : K x 1]
4. 그 결과 얻어진 vector에는 각 label의 score가 담겨 있다. 가장 score가 높은 label을 답으로 내놓는다.

  
* <mark>Point</mark>  적절한 W 설정 $$\rightarrow$$ Loss function 정의하고, Loss를 최소화하는 W 찾기

## SVM(Multiclass Support Vector Machine Loss) - Hinge Loss
### SVM 공식
$$x_i$$를 이미지, $$y_i$$를 해당 이미지에 해당하는 label의 ground truth 값이라고 하면 i번째 테스트 이미지에 대한 SVM 값은 다음과 같다.
  
$$L_i = \sum_{j\neq{y_i}}(max(0, s_j-s_{y_i} + \Delta))$$

여기서 $j\neq{y_i}$이므로 $s_j$는 잘못된 레이블에 매겨진 스코어가 된다. $$\Delta$$는 safty margin이다. 즉 $$L_i$$ 는 $$s_{y_i} + \Delta$$보다 스코어가 높은 레이블이 있으면 0 이상이다. 여기서 몇 가지 질문들이 나온다.



<details>
<summary>Q. Safty margin은 어떻게 설정하는가?</summary>
<div markdown="1">       

A. 잘 못들음

</div>
</details>
<br/>
<details>
<summary>Q. loss의 가능한 min/max값은?</summary>
<div markdown="1">       

A. $$0$$~$$\inf$$

</div>
</details>
<br/>  
<details>
<summary>Q. At initialization W is small so every score is almost 0. What is the loss in this situation? 
</summary>
<div markdown="1">       

A. Number of classes - $$\Delta$$ : sanity check

</div>
</details>
<br/>
    
<details>
<summary> Q. j != {y_i} 조건이 붙지 않는 경우 loss는 어떻게 변화하는가?
</summary>
<div markdown="1">       

A. $$j={y_i}$$인 경우까지 포함할 경우, $$L_i$$ 값이 $$\Delta$$만큼 증가한다. 결과적으로 최종 Loss 값 또한 $$\Delta$$만큼 증가할 것이다.

</div>
</details>
<br/>
  
  <details>
  <summary> +) 원래 function 대신 $$L_i = \sum_{j\neq{y_i}}(max(0, s_j-s_{y_i} + \Delta)^2)$$ 를 이용할 수 있다.
  </summary>
  <div markdown="1">       

  </div>
  </details>
    

### Regularization
문제는 제시된 loss function을 이용해 구한 loss를 0으로 만드는 W가 unique하지 않다는 것이다. loss를 0으로 만드는 어떤 weight W가 있다고 하자. 그렇다면 2W 역시 loss를 0으로 만든다. 즉 loss를 0으로 만드는 W가 여러 개 있다는 것인데, 제시된 loss function은 이 중에서 가장 간단한 것을 고를 수 없다. 따라서 regularization을 한다. 기존의 loss function에 regularization loss를 더하는 것이다. full Multiclass SVM loss는 다음과 같다.
  
   
$$L = (1/N)\sum_{i}(L_i) + \lambda R(W)$$
  
  
$$R(W)$$는 regularization penalty이고, 가장 보편적으로는 squared L2 norm을 사용한다. $$\lambda$$는 hyperparameter이며, 실험(cross-validation)을 통해 결정한다. $$R(W)$$의 종류는 여기<에 정리되어 있을 것.

data loss와 regularization loss에 대한 해석 빈약.. ㅈㅅ 근데 쓰기 귀찮아 하.. 산책가고싶어.. 방금 백신예약했는데 사이트가 너무 이상해서 화가 머리 끝까지 남... ㅇㄴ 글고 또 맥북 이상한 호환성 딸리고 이래가지고 하려던거 너무 오래 걸려 진짜 세상에 날 화나게 하는 프로그램이 너무 많아


## SoftMax classifier - Cross Entropy Loss
 SVM는 각각의 스코어 자체에는 관심을 두지 않고, 정답 클래스의 스코어가 타 클래스 스코어보다 일정 수준 이상이 되는 것만을 목표로 한 loss function이다. 반면 SoftMax classifier는 softmax function을 통해 클래스 별 스코어 확률분포를 만들기 때문에 각각의 스코어를 모두 이용한다. SoftMax function은 다음과 같다.

$$P(Y=k|X=x_i) = e^{s_k}/\sum_j(e^s j)$$

즉 모든 스코어를 2의 지수승 시켜서 양수로 만들고, 그 지수들의 합으로 각 지수화된 스코어를 정규화한다. 목표는 정답 클래스의 확률 값이 1이 되도록 하는 것이다. 수학적인 이점 때문에 여기 Log를 취하고, loss function은 구린 정도를 의미하므로 -를 붙여 준다. 따라서 최종 loss function은 다음과 같은 모양이 되고, 우리의 목표는 -log(정답클래스확률)이 0(-log1) 이 되도록 하는 것이다.

$$L_i = -log(e^{f_{y_i}}/\sum_j(e^{f_j}))$$

앞서 SVM에서와 마찬가지로, 이렇게 구한 $L_i$를 바탕으로 $$L$$을 구할 것이고, 그 과정에서 regularization이 필요하다.
여기서도 몇 가지 질문이 등장한다.

<details>
<summary>Q. loss의 가능한 min/max값은?</summary>
<div markdown="1">       

A. 최솟값은 이론적으로 0이다. 이론적인 이유는, loss가 0이기 위해서는 정답 클래스 확률이 1이어야 하고, 그렇기 위해서는 정답 클래스의 스코어가 무한대여야 하고, 다른 클래스들의 스코어는 음의 무한대여야 하기 때문이다.(유한 정밀도 < 참고. 컴퓨터가 무한대 연산을 잘 하지 못하는 이유).
 최댓값은 무한대이다. 정답 클래스 확률이 0일 때 loss가 가장 클 것인데, 그래프를 생각해 보면 그 때의 loss값이 무한대로 간다. -log(0)을 생각해 봐도 마찬가지. 그러나 이 역시 컴퓨터의 유한 정밀도 때문에 거의 발생하지 않을 것이다.

</div>
</details>
<br/>  
<details>
<summary>Q. At initialization W is small so every score is almost 0. What is the loss in this situation? 
</summary>
<div markdown="1">       

A. $$-log(1/C) = log(C)$$ : sanity check

</div>
</details>
   
## Hinge Loss vs. Cross Entropy Loss


# 3강 : Loss Function 최적화 : Stochastic Gradient Descent
그렇다면 Loss를 최소화하는 W는 어떻게 찾을 수 있을까? 이 장에서는 여러 최적화 방법을 설명하는데, 그것의 아이디어를 잡기 위해서는 아래 Loss function 시각화를 보는 것이 도움이 된다.

## Loss Function의 시각화
 Weight에 따라 Loss 값이 변화하는 것을 시각화 하는 것은 무리가 있다. 왜냐하면 CIFAR-10만 봐도 [10x3073] 크기의 weight 행렬을 가지고 있고, 그렇다면 우리의 loss function 역시 고차원에서 정의될 것이기 때문이다. 따라서 weight 행렬 딱 하나만 뽑아서(강의에서 이 부분을 아예 생략하여 정확히는 모르겠지만, 딱 데이터 하나에 대응하는 그 weight 행렬만 잘라낸다는 뜻인 것 같다) 해당 행렬을 임의의 방향 $$W1$$으로 이동시켜 보자. 즉 $$L(W+aW1)$$ 함수에서 1차원 스칼라에 해당하는 a를 바꾸어 가면서 plot한다. 그 결과는 아래 왼쪽 그림과 같다. 오른쪽 그림은 임의의 방향을 하나 더 잡아서($$W2$$) $$L(W+aW1+bW2)$$의 a,b를 바꿔 가며 plot한 2차원 그래프다.(보라색으로 갈수록 loss가 크고, 빨간색으로 갈수록 loss가 적은 밥공기 형태이다)
 
 
 
 그러니까 우리가 임의의 파란 지점에서 시작했다면, 빨간색 지점으로 걸어들어가야 한다. 손실함수 최적화란 저런 그래프 위에서 임의의 점에서 시작해 조금씩 움직여 가면서, 빨간 지점으로 걸어들어가는 것을 의미한다. 그렇다면 파란 점 위에서 우리는 어떻게 어떤 방향이 빨간 지점으로 가는 방향인지 알 수 있을까? 답을 먼저 이야기하자면, <URed>함수의 Gradient가 빨간 지점으로 가는(함수값이 감소하는) 가장 빠른 방향이다. </URed> 이 결론으로 가기 전에 여러 다른 쓰레기같은 방법들을 알아보자.


그라디언트 하강법에 대한 정리는 내일.. ㅋ
